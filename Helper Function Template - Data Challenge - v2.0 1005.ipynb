{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import auc, roc_curve, classification_report\n",
    "from datetime import datetime, date, time, timedelta\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "#import h2o\n",
    "#from h2o.frame import H2OFrame\n",
    "#from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "#from h2o.grid.grid_search import H2OGridSearch\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style=\"white\",context=\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preview and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preview(df):\n",
    "    # Exploring the data types, number of unique values and missing values\n",
    "    cols = df.columns\n",
    "    print(f\"The dataset consists of {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "    print(f\"The columns are: {df.columns.tolist()}\")\n",
    "    return pd.concat([pd.DataFrame({\n",
    "        \"data_types\":df.dtypes, \n",
    "              \"value_counts\": df.nunique(),\n",
    "             \"null_counts\": df.isnull().sum()}).T,df.iloc[0:3,:]],axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date\n",
    "Should be really careful when the original ts_col is called \"date\" (overlapping with the date column we are about to generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date_factors(df, ts_col, is_datetime):\n",
    "    '''\n",
    "    Assumption: the currect ts_col is a timestamp datatype\n",
    "    \n",
    "    Input:\n",
    "    df (dataframe, target dataframe to be transformed)\n",
    "    ts_col(string, name of the timestamp column)\n",
    "    is_datetime(boolean, whether ts_col is datetime object or not)\n",
    "    \n",
    "    Output:\n",
    "    This function generates hour, hour_of_day, date, weekday, week_of_month, months, year\n",
    "    '''\n",
    "    if is_datetime:\n",
    "        pass\n",
    "    else:\n",
    "        df[ts_col] = list(map(lambda x: datetime.fromisoformat(x),df[ts_col].replace(\":60\",\":59\", regex=True)))\n",
    "\n",
    "    # Hour\n",
    "    df[\"hour\"] = list(map(lambda x: x.hour, df[ts_col]))    \n",
    "\n",
    "    # Hour of day\n",
    "    def get_hourday(x):\n",
    "        if 0<= x < 6:\n",
    "            return \"midnight\"\n",
    "        elif 6<= x < 12:\n",
    "            return \"morning\"\n",
    "        elif 12<= x < 18:\n",
    "            return \"afternoon\"\n",
    "        else:\n",
    "            return \"night\"\n",
    "    df[\"hourday\"] = list(map(lambda x: get_hourday(x), df[\"hour\"]))\n",
    "        \n",
    "    # Date\n",
    "    df[\"date\"] =  list(map(lambda day:day.date(), df[ts_col]))\n",
    "\n",
    "    # Weekday\n",
    "    wkday_dict = {1:\"Mon\",2:\"Tue\",3:\"Wed\",4:\"Thu\",5:\"Fri\",6:\"Sat\",7:\"Sun\"}\n",
    "    df[\"weekday_index\"] = list(map(lambda x: x.date().weekday()+1, df[ts_col]))\n",
    "    df['weekday'] = list(map(lambda x: wkday_dict[x],df[\"weekday_index\"]))\n",
    "\n",
    "    # Week_of_month (assuming 4 weeks in a month)\n",
    "    def get_week(day):\n",
    "        if 1<= day.day < 8:\n",
    "            return (\"first_week\",1)\n",
    "        elif 8<= day.day < 15:\n",
    "            return (\"second_week\",2)\n",
    "        elif 15<= day.day < 22:\n",
    "            return (\"third_week\",3)\n",
    "        else:\n",
    "            return (\"last_week\",4)\n",
    "    df[\"week\"] = list(map(lambda day: get_week(day)[0], df[ts_col]))\n",
    "    df[\"week_index\"] = list(map(lambda day: get_week(day)[1], df[ts_col]))\n",
    "\n",
    "    # Month\n",
    "    month_dict = {1:\"Jan\",2:\"Feb\",3:\"Mar\",4:\"Apr\",5:\"May\",6:\"Jun\",7:\"Jul\",8:\"Aug\",9:\"Sep\",10:\"Oct\",11:\"Nov\",12:\"Dec\"}\n",
    "    df[\"month_index\"] = list(map(lambda day: day.month, df[ts_col]))\n",
    "    df[\"month\"] = list(map(lambda m: month_dict[m], df[\"month_index\"]))\n",
    "\n",
    "    # Year\n",
    "    df[\"year\"] = list(map(lambda x:x.year,df[ts_col]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('{:.2f} Mb, {:.2f} Mb ({:.2f} %)'.format(start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variable Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18, 6))\n",
    "sns.countplot(x='age_range', data=data.sort_values(by = \"age\"),ax=axes[0],palette=sns.color_palette(\"viridis\"))\n",
    "axes[0].set_title('Count Plot of XXX', fontsize=14)\n",
    "axes[0].grid(linestyle=\"--\", alpha=0.2)\n",
    "\n",
    "sns.barplot(x='age_range', y='converted', data=data.sort_values(by = \"age\"), ci=0, ax=axes[1],palette=sns.color_palette(\"viridis\"));\n",
    "axes[1].set_title('XXX', fontsize=14)\n",
    "axes[1].grid(linestyle=\"--\", alpha=0.2)\n",
    "\n",
    "fig.suptitle(\"XX\", fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Variable Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of different sources\n",
    "# palette=sns.color_palette(\"viridis\")?\n",
    "\n",
    "sns.set(style=\"white\",context=\"talk\")\n",
    "grouped = data.groupby('purchase_value')[\"class\"].mean().reset_index()\n",
    "hist_kws={'histtype': 'bar', 'alpha': 0.2}\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18, 6))\n",
    "sns.distplot(data[data['class'] == 0]['purchase_value'],\n",
    "             label='Not Fraud', ax=axes[0], hist_kws=hist_kws)\n",
    "sns.distplot(data[data['class'] == 1]['purchase_value'], \n",
    "             label='Fraud', ax=axes[0], hist_kws=hist_kws)\n",
    "axes[0].set_title('Density of purchase_value', fontsize=16)\n",
    "axes[0].set_xlabel('purchase_value',fontsize = 16)\n",
    "axes[0].legend()\n",
    "axes[0].grid(linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "\n",
    "#sns.relplot(x = \"purchase_value\",y=\"class\", data = data,kind = \"line\",ci = None,ax = axes[1])\n",
    "axes[1].plot(grouped['purchase_value'], grouped['class'])\n",
    "axes[1].set_title('Fraudulent Rate vs. purchase_value', fontsize=16)\n",
    "axes[1].set_xlabel('purchase_value',fontsize = 16)\n",
    "axes[1].set_ylabel('Fraudulent Rate',fontsize = 16)\n",
    "axes[1].grid(linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "fig.suptitle(\"Fraudulent Rate fluctuates around 9% but gets more volatile as value becomes larger\", fontsize = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Distribution being Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_normal_dist(data1, data2, method):\n",
    "    '''\n",
    "    This function checks whether two series (data1 and data2) is sampled from normal distribution \n",
    "    via different methods to ensure robustness.\n",
    "    '''\n",
    "    if method == 'ks_test':\n",
    "        # 1. Check Kolmogorov-Smirnov test result\n",
    "        print(\"KS-Test for the treatment group: \",stats.kstest(data1, 'norm'))\n",
    "        print(\"KS-Test for the control group: \",stats.kstest(data2, 'norm'),\"\\n\")\n",
    "    elif method == 'shapiro':\n",
    "        # 2. Check Shaporio-Wilk test result\n",
    "        print(f'Shapiro–Wilk test for the treatment group: The p-value is {stats.shapiro(data1)[1]}')\n",
    "        print(f'Shapiro–Wilk test for the control group: The p-value is {stats.shapiro(data2)[1]}')\n",
    "    elif method == 'qq_plot':\n",
    "        # 3. Visualize normality using Q-Q plot\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18, 6))\n",
    "        stats.probplot(data1, dist=\"norm\", plot=axes[0])\n",
    "        axes[0].set_title(\"Treatment Group: Q-Q Plot for Active Minutes\", fontsize = 16)\n",
    "        stats.probplot(data2, dist=\"norm\", plot=axes[1])\n",
    "        axes[1].set_title(\"Control Group: Q-Q Plot for Active Minutes\", fontsize = 16)\n",
    "        fig.suptitle(\"Q-Q Plot Normality Check: Total minutes per user in each group\", fontsize = 20)\n",
    "    elif method == 'hist':\n",
    "        # 4. Visualize normality using histogram\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(22,10))\n",
    "        sns.distplot(data1,\n",
    "                  hist_kws = {'histtype': 'bar', \"color\": 'green','alpha': 0.4},\n",
    "                  kde_kws={\"lw\": 2,\"alpha\":0.8,\"linestyle\":'--'},\n",
    "                  ax=axes[0])\n",
    "        axes[0].set_xlabel('Active Minutes') \n",
    "        axes[0].set_ylabel('Probability')\n",
    "        axes[0].set_title(f'Treatment Group: Histogram for Active Minutes',fontsize = 16) \n",
    "        sns.distplot(data2,\n",
    "                  hist_kws = {'histtype': 'bar', \"color\": 'green','alpha': 0.4},\n",
    "                  kde_kws={\"lw\": 2,\"alpha\":0.8,\"linestyle\":'--'},\n",
    "                  ax=axes[1])\n",
    "        axes[1].set_xlabel('Active Minutes')  \n",
    "        axes[1].set_ylabel('Probability') \n",
    "        axes[1].set_title(f'Control Group: Histogram for Active Minutes',fontsize = 16) \n",
    "        \n",
    "    elif method == 'hist_norm':\n",
    "        # 5. Visualize normality using histogram (normal distribution as fde)\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(22,10))\n",
    "        num_bins = 50  \n",
    "\n",
    "        mu =np.mean(data1) \n",
    "        sigma =np.std(data1) \n",
    "        n, bins, patches = axes[0].hist(data1, num_bins,normed=1, facecolor='green', alpha=0.5) \n",
    "        y = norm.pdf(bins, mu, sigma) \n",
    "        axes[0].plot(bins, y, 'b--') \n",
    "        axes[0].set_xlabel('Active Minutes')\n",
    "        axes[0].set_ylabel('Probability')\n",
    "        axes[0].set_title(f'Treatment Group: Histogram for Active Minutes (mu = {round(mu)}; sigma = {round(sigma)})',fontsize = 16) \n",
    "\n",
    "        mu =np.mean(data2) \n",
    "        sigma =np.std(data2)  \n",
    "        n, bins, patches = axes[1].hist(data2, num_bins,normed=1, facecolor='green', rwidth = 0.7,alpha=0.5) \n",
    "        y = norm.pdf(bins, mu, sigma)\n",
    "        axes[1].plot(bins, y, 'b--') \n",
    "        axes[1].set_xlabel('Active Minutes') \n",
    "        axes[1].set_ylabel('Probability')\n",
    "        axes[1].set_title(f'Control Group: Histogram for Active Minutes (mu = {round(mu)}; sigma = {round(sigma)})',fontsize = 16) \n",
    "        fig.suptitle(\"Histogram Normality Check: Total minutes per user in each group\\n Note: The blue curve depicts normal distribution \", fontsize = 20)        \n",
    "    else:\n",
    "        print(\"Unrecognized Method\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Homogeneous Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_homo_var(data1, data2):\n",
    "    '''\n",
    "    This function checks the homogeneous variance assumption for independent t-test, \n",
    "    which is required if implementing AB experiment.\n",
    "    \n",
    "    '''\n",
    "    # 1: Check levene test result\n",
    "    t,p = stats.levene(data1,data2)\n",
    "    print(f\"Levene variance test: t={round(t,3)}, p={round(p,3)}\")\n",
    "    if p<0.05:\n",
    "        print(\"----variance of the two group doesn't equal, reject the null hypothesis----\")\n",
    "        t,p = stats.ttest_ind(data1,data2, equal_var = False)\n",
    "    else:\n",
    "        t,p = stats.ttest_ind(data1,data2)\n",
    "    print(f\"Independent t-test: t={round(t,3)}, p={round(p,3)}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Sampling Distribution being Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samp_dist(data, metric_col, dim_col, group_col,id_col,fig_size = [22,10],matrix=[1,2]):\n",
    "    fig, axes = plt.subplots(nrows=matrix[0], ncols=matrix[1], figsize=(fig_size[0], fig_size[1]))\n",
    "\n",
    "    SIZE_EXPT = data[data[group_col] == 1][id_col].nunique()\n",
    "    SIZE_CTRL = data[data[group_col] == 0][id_col].nunique()\n",
    "\n",
    "    tmp_by_dim = data.groupby(by=[dim_col,group_col,id_col])[metric_col].sum().reset_index().groupby(by= [dim_col,group_col]).agg(\n",
    "        {id_col:\"nunique\",metric_col:\"mean\"}).reset_index().sort_values(id_col,ascending = False)\n",
    "    tmp_by_dim.columns = [dim_col,group_col,\"cnt_\"+id_col,metric_col]\n",
    "    tmp_by_dim[dim_col+'_pct'] = 0\n",
    "    tmp_by_dim.loc[tmp_by_dim[group_col] == 1,dim_col+'_pct'] = tmp_by_dim[tmp_by_dim[group_col] == 1][\"cnt_\"+id_col]/SIZE_EXPT\n",
    "    tmp_by_dim.loc[tmp_by_dim[group_col] == 0,dim_col+'_pct'] = tmp_by_dim[tmp_by_dim[group_col] == 0][\"cnt_\"+id_col]/SIZE_CTRL\n",
    "\n",
    "    sns.barplot(x=dim_col, y = dim_col+'_pct', hue = group_col, data=tmp_by_dim,\n",
    "                ax=axes[0], palette=sns.color_palette(\"viridis\", 2))\n",
    "    axes[0].set_title(f'Sampling Distribution by {dim_col}', fontsize=18)\n",
    "    axes[0].grid(linestyle=\"--\", alpha=0.2)\n",
    "    axes[0].legend(title = \"Ctr=0/Exp=1\",loc = 1)\n",
    "\n",
    "    sns.barplot(x=dim_col, y=metric_col,hue = group_col, data=tmp_by_dim, \n",
    "                ci=0, ax=axes[1], palette=sns.color_palette(\"viridis\", 2))\n",
    "    axes[1].set_title(f'Active Minutes per User by {dim_col}', fontsize=18)\n",
    "    axes[1].grid(linestyle=\"--\", alpha=0.2)\n",
    "    axes[1].legend(title = \"Ctr=0/Exp=1\",loc = 1)\n",
    "\n",
    "    fig.suptitle(f\"Random Sampling Check on {dim_col}: Comparing Experiment/Control Group\",fontsize = 20)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levene_t_test(data1, data2):\n",
    "    # Step1: Check normal distribution assumption\n",
    "    print(\"Data1: KS-Test\",stats.kstest(data1, 'norm'))\n",
    "    print(\"Data1: KS-Test\",stats.kstest(data2, 'norm'),\"\\n\")\n",
    "    \n",
    "    # Step2: Check equality of variance (not required in paired t-test), only required in independent t-test\n",
    "    t,p = stats.levene(data1,data2)\n",
    "    print(f\"Levene variance test: t={round(t,3)}, p={round(p,3)}\")\n",
    "    if p<0.05:\n",
    "        print(\"----variance of the two group doesn't equal, reject the null hypothesis----\")\n",
    "        t,p = stats.ttest_ind(data1,data2, equal_var = False)\n",
    "    else:\n",
    "        t,p = stats.ttest_ind(data1,data2)\n",
    "    print(f\"Independent t-test: t={round(t,3)}, p={round(p,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def anova_test(df, col, target_col):\n",
    "    '''\n",
    "    Assumption:\n",
    "    df has date column\n",
    "    \n",
    "    df: test dataframe (pandas df)\n",
    "    col: the column to be tested (string)\n",
    "    '''\n",
    "    args = []\n",
    "    for value in df[col].unique():\n",
    "        args.append(df[df[col] == value].groupby(\"date\")[target_col].mean().values)\n",
    "    f, p = stats.f_oneway(*args)\n",
    "\n",
    "    print(f'For {col}: One-way ANOVA')\n",
    "    print(f\"Number of pairs of samples: {len(args[0])}\")\n",
    "    print('=============')\n",
    "\n",
    "    print('F value:', round(f,4))\n",
    "    print('P value:', round(p,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def sampleSize_twoGroups(D, alpha=0.05, beta=0.2, sigma1=1, sigma2=1):\n",
    "    '''\n",
    "    Sample size for two groups. The formula corresponds to Eq 6.4 in the book.\n",
    "    '''\n",
    "     \n",
    "    n = np.round((norm.ppf(1-alpha/2.) + norm.ppf(1-beta))**2 * (sigma1**2 + sigma2**2) / D**2)\n",
    "     \n",
    "    print(('In order to detect a change of {0} between groups with an SD of {1} and {2},'.format(D, sigma1, sigma2)))\n",
    "    print(('with significance {0} and test-power {1}, you need in each group at least {2:d} subjects.'.format(alpha, 100*(1-beta), int(n))))\n",
    "     \n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference-in-Difference Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "def get_did_result(df,Y,time_var,group_var,time_group_var):\n",
    "    did_est = smf.ols(formula=f'{Y} ~ {time_var} + {group_var} + {time_group_var}', data=df).fit() \n",
    "    print(did_est.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold out 20% as validation dataset for evaluation purpose\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA for dimension reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def pca_viz(data):\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    pca = pca.fit(data)\n",
    "    pca_output = pca.transform(data)\n",
    "\n",
    "    # standardize the results\n",
    "    return pd.DataFrame(StandardScaler().fit_transform(pca_output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans\n",
    "GridSearch to select the best K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score,silhouette_samples\n",
    "# determine the best number of clusters\n",
    "# Please replace the pca_data as the actual data in use\n",
    "clusters = range(2, 20)\n",
    "inertias = []\n",
    "silhouettes = []\n",
    "\n",
    "for n_clusters in clusters:\n",
    "  # Set n_init=10 to run k-means clustering algorithm 10 times independently\n",
    "  # with different centroids to choose the final model with the lowest SSE\n",
    "    kmeans = KMeans(n_clusters = n_clusters, init='k-means++', n_init = 10, max_iter=300,random_state=123, n_jobs=-1)\n",
    "    kmeans = kmeans.fit(pca_data)\n",
    "    label = kmeans.predict(pca_data)\n",
    "    \n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouettes.append(silhouette_score(pca_data, label))\n",
    "    \n",
    "# visualization\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(18, 6))\n",
    "ax[0].plot(clusters, inertias, 'o-',color = \"yellowgreen\")\n",
    "ax[0].set_title(\"Sum of Squared Distances: Decreasing constantly\",fontsize = 16)\n",
    "ax[0].axhline(y=inertias[4],ls=\"--\",c=\"yellowgreen\",alpha = 0.7)\n",
    "ax[0].axvline(x=6,ls=\"--\",c=\"yellowgreen\",alpha = 0.7)\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(clusters, silhouettes, 'o-',color = \"orange\")\n",
    "ax[1].grid(True)\n",
    "ax[1].axhline(y=silhouettes[4],ls=\"--\",c=\"orange\",alpha = 0.7)\n",
    "ax[1].axvline(x=6,ls=\"--\",c=\"orange\",alpha = 0.7)\n",
    "ax[1].set_title(\"Silhouette Coefficient: 6 clusters seem optimal\",fontsize = 16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample to recreate a balanced training set\n",
    "def undersample(data, target_col):\n",
    "    data_neg = data[data[target_col] == 0].sample(n=len(data[data[target_col] == 1]), random_state=111)\n",
    "    return pd.concat([data_neg, data[data[target_col] == 1]],axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier + RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_clf = RandomForestClassifier(oob_score = True, max_features='auto' ,random_state=10)\n",
    "rf_parameters = {\"n_estimators\":[50,80,100], \"max_depth\":[3,5,7], \"min_samples_split\" :[2,5,8], \"min_samples_leaf\":[2,5,8]}\n",
    "rf_random_search = RandomizedSearchCV(rf_clf, rf_parameters, n_jobs = -1, cv = 2, scoring = \"roc_auc\", n_iter = 15)\n",
    "rf_random_search.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "print(rf_random_search.best_params_)\n",
    "rf_clf_best = rf_random_search.best_estimator_\n",
    "print(rf_clf_best.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "def rfe_cv(clf, x_train, y_train, min_features_to_select):\n",
    "\n",
    "    rfecv = RFECV(estimator = clf, step=1, cv=StratifiedKFold(2),min_features_to_select = min_features_to_select,\n",
    "                  scoring='roc_auc')\n",
    "\n",
    "    rfecv.fit(x_train, y_train.values.ravel())\n",
    "    print(f\"Optimal number of features : {rfecv.n_features_}, the optimal roc_auc score: {rfecv.grid_scores_.max()}\\n\")\n",
    "    print(f\"The {rfecv.n_features_} features selected: {x_train.columns[rfecv.support_].values}\")\n",
    "\n",
    "    # Plot number of features VS. cross-validation scores\n",
    "    plt.figure(figsize = (12,6))\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "    plt.plot(range(min_features_to_select,\n",
    "                   len(rfecv.grid_scores_) + min_features_to_select),\n",
    "             rfecv.grid_scores_, marker = \"o\", markersize = 3)\n",
    "    #plt.plot(range(len(rfecv.grid_scores_)),\n",
    "     #        rfecv.grid_scores_, marker = \"o\", markersize = 3)\n",
    "    plt.grid(linestyle=\"--\", alpha=0.3)\n",
    "    plt.axvline(x = rfecv.n_features_, ls=\":\",c=\"green\") \n",
    "    #plt.axhline(y = rfecv.grid_scores_.max(), ls=\":\", c=\"green\")\n",
    "    plt.text(rfecv.n_features_, rfecv.grid_scores_.max(),(rfecv.n_features_,round(rfecv.grid_scores_.max(),4)),color='green')\n",
    "    plt.show()\n",
    "    return rfecv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rfecv = rfe_cv(rf_clf_best, x_train, y_train, min_features_to_select = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_imp = pd.DataFrame({\"importance\":[round(x,4) for x in rf_clf_best.feature_importances_],\n",
    "                        \"feature\":x_train.columns[rf_rfecv.support_].values}).sort_values(by = \"importance\", ascending = False)\n",
    "fig = plt.figure(figsize = (14,14))\n",
    "sns.barplot(x = \"importance\", y = \"feature\", data = fea_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classification report\n",
    "train_true = y_train\n",
    "valid_true = y_valid\n",
    "train_pred = rf_clf_best.predict_proba(x_train)[:,1]\n",
    "valid_pred = rf_clf_best.predict_proba(x_valid)[:,1]\n",
    "\n",
    "# Make predictions\n",
    "train_fpr, train_tpr, _ = roc_curve(train_true, train_pred)\n",
    "valid_fpr, valid_tpr, _ = roc_curve(valid_true, valid_pred)\n",
    "train_auc = np.round(auc(train_fpr, train_tpr), 3)\n",
    "valid_auc = np.round(auc(valid_fpr, valid_tpr), 3)\n",
    "\n",
    "# F1-score = 2 * precision*recall / (precision+recall)\n",
    "print(classification_report(y_true=valid_true, y_pred=(valid_pred > 0.5).astype(int),\n",
    "                            target_names = [\"negative:0\",\"positive:1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC/AUC Plot**\n",
    "We expect the train and test curve to converge (otherwise we tend to have overfitting problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(train_fpr, train_tpr, label='Train AUC: ' + str(train_auc))\n",
    "ax.plot(valid_fpr, valid_tpr, label='Test AUC: ' + str(valid_auc))\n",
    "ax.plot([0, 1], [0, 1], ls=\"--\", c=\".3\")\n",
    "ax.set_xlabel('False Positive Rate', fontsize=14)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=14)\n",
    "ax.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:58599</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>8.35 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:58599' processes=4 threads=8, memory=8.35 GB>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()  # set up local cluster on your laptop\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.837px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
